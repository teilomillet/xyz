+++
title = 'about'
date = '1997-06-01'
dateformat = 'January 2006'
draft = false
+++

## who

I'm Teïlo Millet — a self-taught AI engineer based in Paris. I'm interested in research around large language models: reinforcement learning, alignment, safety, and everything in between.

## now

consultant data & AI at [OCTO Technology](https://www.octo.com).

## before

I tried to build [enzu](https://github.com/teilomillet/enzu) as a company at [STATION F](https://stationf.co) (Fighters Program). enzu is a toolkit for running LLM tasks with hard spending limits — budgets as laws of physics, not best-effort throttling. typed outcomes, async delegation, stress testing, and retry tracking. the idea: if you want to delegate a task to an LLM autonomously, you need guaranteed cost caps.

## open source

[textpolicy](https://github.com/teilomillet/textpolicy) — reinforcement learning for text generation on Apple Silicon (MLX). GRPO, GSPO, LoRA fine-tuning.

[enzu](https://github.com/teilomillet/enzu) — budget-controlled recursive language model (RLM) execution in Python. hard caps on tokens, time, and cost. typed outcomes for every run.

[gollm](https://github.com/teilomillet/gollm) — unified Go interface for LLM providers. prompt optimization, structured output, model comparison.

[raggo](https://github.com/teilomillet/raggo) — production-ready RAG library in Go. document loading, semantic chunking, vector storage.

## models

[MiniMerlin-3B](https://huggingface.co/teilomillet/MiniMerlin-3B) — reached global top 5 in the 3B parameter category on HuggingFace's Open LLM Leaderboard.

## writing

[intuitus](https://teilomillet.com) — a French newsletter on AI, prompt engineering, and the tech industry.

## links

[github](https://github.com/teilomillet) · [huggingface](https://huggingface.co/teilomillet) · [x](https://x.com/teilomillet) · [linkedin](https://linkedin.com/in/teilomillet) · [teilomillet@gmail.com](mailto:teilomillet@gmail.com)
